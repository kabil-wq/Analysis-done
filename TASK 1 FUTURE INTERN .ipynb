{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b88c0510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training set:\n",
      " PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "Data cleaning complete. Cleaned datasets saved as 'train_cleaned.csv' and 'test_cleaned.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv(r\"C:\\Users\\kabil\\Downloads\\train.csv\")\n",
    "test_df = pd.read_csv(r\"C:\\Users\\kabil\\Downloads\\test.csv\")\n",
    "\n",
    "# Step 1: Handling Missing Values\n",
    "\n",
    "# Identify columns with missing values\n",
    "missing_values_count = train_df.isnull().sum()\n",
    "print(\"Missing values in training set:\\n\", missing_values_count)\n",
    "\n",
    "# Removing rows with missing target variable (if applicable)\n",
    "# If 'Survived' is your target variable and cannot be missing\n",
    "train_df = train_df.dropna(subset=['Survived'])\n",
    "\n",
    "# Handling missing values using mean imputation for numerical features\n",
    "# Exclude 'Survived' column from numerical columns\n",
    "num_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "num_cols.remove('Survived')\n",
    "\n",
    "# Get numeric columns for the test set as well (excluding target column)\n",
    "test_num_cols = test_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Impute missing values in numeric columns\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "train_df[num_cols] = num_imputer.fit_transform(train_df[num_cols])\n",
    "test_df[test_num_cols] = num_imputer.transform(test_df[test_num_cols])\n",
    "\n",
    "# Handling missing values using the most frequent strategy for categorical features\n",
    "cat_cols = train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Impute missing values in categorical columns\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "train_df[cat_cols] = cat_imputer.fit_transform(train_df[cat_cols])\n",
    "test_df[cat_cols] = cat_imputer.transform(test_df[cat_cols])\n",
    "\n",
    "# Step 2: Handling Outliers\n",
    "\n",
    "# Define a function to remove outliers based on Z-score\n",
    "def remove_outliers(df, cols, threshold=3):\n",
    "    z_scores = np.abs((df[cols] - df[cols].mean()) / df[cols].std())\n",
    "    return df[(z_scores < threshold).all(axis=1)]\n",
    "\n",
    "# Apply the function to the numerical columns\n",
    "train_df = remove_outliers(train_df, num_cols)\n",
    "test_df = remove_outliers(test_df, test_num_cols)\n",
    "\n",
    "# Step 3: Encoding Categorical Variables\n",
    "\n",
    "# Encoding categorical variables using one-hot encoding\n",
    "train_df = pd.get_dummies(train_df, columns=cat_cols, drop_first=True)\n",
    "test_df = pd.get_dummies(test_df, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# Align test set with training set\n",
    "# Ensure both dataframes have the same columns\n",
    "test_df = test_df.reindex(columns=train_df.columns, fill_value=0)\n",
    "\n",
    "# Exclude the target column from the test set\n",
    "if 'Survived' in test_df.columns:\n",
    "    test_df = test_df.drop(columns=['Survived'])\n",
    "\n",
    "# Step 4: Scaling Numerical Features\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_df[num_cols] = scaler.fit_transform(train_df[num_cols])\n",
    "test_df[num_cols] = scaler.transform(test_df[num_cols])\n",
    "\n",
    "# Step 5: Saving the Cleaned Datasets\n",
    "\n",
    "train_df.to_csv('train_cleaned.csv', index=False)\n",
    "test_df.to_csv('test_cleaned.csv', index=False)\n",
    "\n",
    "print(\"Data cleaning complete. Cleaned datasets saved as 'train_cleaned.csv' and 'test_cleaned.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
